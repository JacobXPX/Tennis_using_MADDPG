{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "The environment is already saved in the Workspace and can be accessed at the file path provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "def MSG(txt):\n",
    "    print('\\n',datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), str(txt))\n",
    "from maddpg_agents import DDPGAgent, MADDPG\n",
    "import sys\n",
    "env = UnityEnvironment(file_name=\"data/Tennis_Linux/Tennis.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "obs_size = states.shape[1]\n",
    "state_size = obs_size * states.shape[0]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], obs_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modified DDPG\n",
    "\n",
    "[MADDPG](https://arxiv.org/abs/1706.02275) is an actor-critic, model-free deep reinforcement learning methods for multi-agent domains.\n",
    "![MADDPG](src/img/maddpg.png)\n",
    "\n",
    "Details of our algorithm:\n",
    "\n",
    "1. 2-hidden layer (relu+bn) + tanh outlayer Actor Netwok\n",
    "2. 2-hidden layer (relu+bn) + Linear outlayer  Critic Netwok\n",
    "3. independent Critic/Actor Network and OuNoise process (with noise reduce factor) for each agent\n",
    "\n",
    "Some hyper-parameters:\n",
    "\n",
    "Hyper-Parameter | Value | Description\n",
    "----------|-----------|--------------\n",
    "BUFFER_SIZE | 2e6  | replay buffer size\n",
    "BATCH_SIZE | 1024        | minibatch size\n",
    "GAMMA | 0.99           | discount factor\n",
    "TAU | 1e-3              | for soft update of target parameters\n",
    "LR_ACTOR | 1e-3         | learning rate of the actor\n",
    "LR_CRITIC | 1e-3        | learning rate of the critic\n",
    "WEIGHT_DECAY | 1e-5        | L2 weight decay\n",
    "UPDATE_EVERY | 100       | how often to update the network\n",
    "LEARN_TIMES | 50        | how many times to learn each avtive step\n",
    "NOISE_REDUCE | 0.9997 | reduce factor of noise in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2018-11-15 01:15:05: start!\n",
      "Episode 100\tWinner is agent 0\tAverage Score on 100 Episode: 0.005\n",
      "Episode 200\tWinner is agent 0\tAverage Score on 100 Episode: 0.005\n",
      "Episode 300\tWinner is agent 0\tAverage Score on 100 Episode: 0.005\n",
      "Episode 400\tWinner is agent 1\tAverage Score on 100 Episode: 0.010\n",
      "Episode 500\tWinner is agent 1\tAverage Score on 100 Episode: 0.022\n",
      "Episode 600\tWinner is agent 1\tAverage Score on 100 Episode: 0.029\n",
      "Episode 700\tWinner is agent 1\tAverage Score on 100 Episode: 0.037\n",
      "Episode 800\tWinner is agent 1\tAverage Score on 100 Episode: 0.039\n",
      "Episode 900\tWinner is agent 1\tAverage Score on 100 Episode: 0.055\n",
      "Episode 1000\tWinner is agent 1\tAverage Score on 100 Episode: 0.087\n",
      "Episode 1100\tWinner is agent 1\tAverage Score on 100 Episode: 0.112\n",
      "Episode 1200\tWinner is agent 0\tAverage Score on 100 Episode: 0.157\n",
      "Episode 1300\tWinner is agent 0\tAverage Score on 100 Episode: 0.195\n",
      "Episode 1400\tWinner is agent 0\tAverage Score on 100 Episode: 0.239\n",
      "Episode 1500\tWinner is agent 0\tAverage Score on 100 Episode: 0.345\n",
      "Episode 1600\tWinner is agent 0\tAverage Score on 100 Episode: 0.228\n",
      "Episode 1700\tWinner is agent 0\tAverage Score on 100 Episode: 0.270\n",
      "Episode 1800\tWinner is agent 0\tAverage Score on 100 Episode: 0.231\n",
      "Episode 1900\tWinner is agent 0\tAverage Score on 100 Episode: 0.398\n",
      "Episode 2000\tWinner is agent 0\tAverage Score on 100 Episode: 0.552\n",
      "Episode 2100\tWinner is agent 1\tAverage Score on 100 Episode: 0.508\n",
      "Episode 2200\tWinner is agent 0\tAverage Score on 100 Episode: 0.433\n",
      "Episode 2300\tWinner is agent 1\tAverage Score on 100 Episode: 0.556\n",
      "Episode 2400\tWinner is agent 1\tAverage Score on 100 Episode: 0.544\n",
      "Episode 2500\tWinner is agent 1\tAverage Score on 100 Episode: 0.477\n",
      "Episode 2600\tWinner is agent 1\tAverage Score on 100 Episode: 0.664\n",
      "Episode 2700\tWinner is agent 1\tAverage Score on 100 Episode: 0.616\n",
      "Episode 2800\tWinner is agent 1\tAverage Score on 100 Episode: 1.074\n",
      "Episode 2900\tWinner is agent 1\tAverage Score on 100 Episode: 0.682\n",
      "Episode 3000\tWinner is agent 0\tAverage Score on 100 Episode: 0.891\n",
      "Episode 3100\tWinner is agent 0\tAverage Score on 100 Episode: 0.800\n",
      "Episode 3200\tWinner is agent 0\tAverage Score on 100 Episode: 0.976\n",
      "Episode 3300\tWinner is agent 0\tAverage Score on 100 Episode: 0.588\n",
      "Episode 3400\tWinner is agent 0\tAverage Score on 100 Episode: 0.640\n",
      "Episode 3500\tWinner is agent 0\tAverage Score on 100 Episode: 1.059\n",
      "\n",
      " 2018-11-15 07:02:43: end!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba7484d630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_list = [\n",
    "    DDPGAgent(obs_size, state_size, action_size, random_seed = 2018),\n",
    "    DDPGAgent(obs_size, state_size, action_size, random_seed = 2019),\n",
    "]\n",
    "agents = MADDPG(agent_list)\n",
    "\n",
    "def maddpg(env, agents, n_episodes=3500, max_t=2000, print_every=100):\n",
    "    MSG('start!')\n",
    "    brain_name = env.brain_names[0]\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores_idx_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    best_score = 0.\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        obs_tuple = env_info.vector_observations\n",
    "        agents.reset()\n",
    "        agent_scores = np.zeros(len(agents.maddpg_agent))\n",
    "        for t in range(max_t):\n",
    "            action_tuple = agents.act(obs_tuple)                    # select an action (for each agent)\n",
    "            env_info = env.step(action_tuple)[brain_name]           # send all actions to tne environment\n",
    "            next_obs_tuple = env_info.vector_observations           # get next state (for each agent)\n",
    "            reward_tuple = env_info.rewards                         # get reward (for each agent)\n",
    "            done_tuple = env_info.local_done                        # see if episode finished\n",
    "            agent_scores += reward_tuple\n",
    "            agents.step(obs_tuple, action_tuple, reward_tuple, next_obs_tuple, done_tuple)\n",
    "            obs_tuple = next_obs_tuple                              # roll over states to next time step\n",
    "            if np.any(done_tuple):                                  # exit loop if episode finished\n",
    "                break\n",
    "        score, idx = np.max(agent_scores), np.argmax(agent_scores)\n",
    "        scores_deque.append(score)\n",
    "        scores_idx_deque.append(idx)\n",
    "        scores.append(score)\n",
    "        if score > best_score:\n",
    "            torch.save(agents.maddpg_agent[idx].actor_local.state_dict(), 'model/checkpoint_actor.pth')\n",
    "            torch.save(agents.maddpg_agent[idx].critic_local.state_dict(), 'model/checkpoint_critic.pth')\n",
    "            best_score = score\n",
    "        if i_episode % (print_every) == 0:\n",
    "            print('\\rEpisode {}\\tWinner is agent {}\\tAverage Score on 100 Episode: {:.3f}'.format(i_episode, int(round(np.mean(scores_idx_deque))), np.mean(scores_deque)))\n",
    "    MSG('end!') \n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = maddpg(env, agents)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Have a look at well-trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from maddpg_agents import DDPGAgent, MADDPG\n",
    "env = UnityEnvironment(file_name='data/Tennis_Linux/Tennis.x86_64')\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "obs_size = states.shape[1]\n",
    "state_size = obs_size * states.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_list = [\n",
    "    DDPGAgent(obs_size, state_size, action_size, random_seed = 2018),\n",
    "    DDPGAgent(obs_size, state_size, action_size, random_seed = 2019),\n",
    "]\n",
    "agents = MADDPG(agent_list)\n",
    "# load trained model\n",
    "agents.maddpg_agent[0].actor_local.load_state_dict(torch.load('model/checkpoint_actor.pth'))\n",
    "agents.maddpg_agent[1].actor_local.load_state_dict(torch.load('model/checkpoint_actor.pth'))\n",
    "state = env.reset()\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "obs_tuple = env_info.vector_observations\n",
    "for t in range(2000):\n",
    "    action_tuple = agents.act(obs_tuple)\n",
    "    env_info = env.step(action_tuple)[brain_name]\n",
    "    next_obs_tuple = env_info.vector_observations\n",
    "    done_tuple = env_info.local_done\n",
    "    obs_tuple = next_obs_tuple\n",
    "    if np.any(done_tuple):\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step\n",
    "\n",
    "To improve the agent's performance:\n",
    "\n",
    "1. During my experiments, I found that when I do `torch.nn.utils.clip_grad_norm_()` by 1 or 0.5, the performance is the same, so I think I can investigate in the gradient scales and do experiments on using L1 norm or `torch.nn.utils.clip_grad_value_()`.\n",
    "\n",
    "2. I will make the network large to see how it will affect the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
